{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def classify_text(text, possible_outputs):\n",
    "    framed_texts = [f\"{text} This text is {output}.\" for output in possible_outputs]\n",
    "    encoded_inputs = [tokenizer.encode(t, return_tensors=\"pt\").to(device) for t in framed_texts]\n",
    "    \n",
    "    logits_for_outputs = []\n",
    "\n",
    "    for encoded_input in encoded_inputs:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(encoded_input)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        logits_for_outputs.append(logits[0, -1, :].squeeze().cpu().numpy())\n",
    "    \n",
    "    token_ids = [tokenizer.encode(output)[0] for output in possible_outputs]\n",
    "    class_logits = [logits[token_id] for logits, token_id in zip(logits_for_outputs, token_ids)]\n",
    "    return possible_outputs[class_logits.index(max(class_logits))]\n",
    "\n",
    "possible_classes = [\"positive\", \"negative\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The term \"AI\" is used to describe a type of artificial intelligence that is capable of performing tasks that humans cannot perform.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_name = 'gpt2-medium'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def summarize(text, max_length=150):\n",
    "    prompt = f\"Summarize the following text: \\\"{text}\\\" Summary: \"\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    input_ids = input_ids.to('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, temperature=0.7, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    summary = generated_text.split(\"Summary: \")[-1]\n",
    "\n",
    "    return summary\n",
    "\n",
    "article = \"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \\\"intelligent agents\\\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\"\n",
    "print(summarize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/minhaoj2/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf115cb54de4543913df13c278b6ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [19:40<00:00, 57.07it/s]\n"
     ]
    }
   ],
   "source": [
    "sst2 = load_dataset(\"glue\", \"sst2\")\n",
    "train_data = sst2['train']\n",
    "\n",
    "ground_truth = []\n",
    "pred_labels = []\n",
    "\n",
    "for data in tqdm(train_data):\n",
    "    logits = data['label']\n",
    "    prediction = classify_text(data['sentence'], possible_classes)\n",
    "    if prediction == \"positive\":\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "    ground_truth.append(logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.450608026845239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(ground_truth, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
