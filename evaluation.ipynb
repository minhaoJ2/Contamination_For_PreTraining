{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_dataset, load_metric\n",
    "from rouge import Rouge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-medium\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.bos_token\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# config = GPT2Config()\n",
    "# model = GPT2LMHeadModel(config)\n",
    "# checkpoint = torch.load(\"/shared/data2/minhaoj2/gpt-2-original/pytorch_model.bin\")\n",
    "# model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"Preparing Model ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_prompt_list = [\"This text is\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agnews_1(model, tokenizer, device=device):\n",
    "    def classify_text(text, possible_outputs):\n",
    "        framed_texts = [f\"{text} This text is {output}.\" for output in possible_outputs]\n",
    "        encoded_inputs = [tokenizer.encode(t, return_tensors=\"pt\").to(device) for t in framed_texts]\n",
    "        \n",
    "        logits_for_outputs = []\n",
    "\n",
    "        for encoded_input in encoded_inputs:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(encoded_input)\n",
    "                logits = outputs.logits\n",
    "            logits_for_outputs.append(logits[0, -1, :].squeeze().cpu().numpy())\n",
    "        \n",
    "        token_ids = [tokenizer.encode(output)[0] for output in possible_outputs]\n",
    "        class_logits = [logits[token_id] for logits, token_id in zip(logits_for_outputs, token_ids)]\n",
    "        return possible_outputs[class_logits.index(max(class_logits))]\n",
    "\n",
    "    possible_outputs = [\"world\", \"sports\", \"business\", \"sci/tech\"]\n",
    "    dataset = load_dataset(\"ag_news\", split=\"test\").select(range(100))\n",
    "\n",
    "    ground_truth = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for data in tqdm(dataset):\n",
    "        logits = data['label']\n",
    "        prediction = classify_text(data['text'], possible_outputs)\n",
    "        pred_labels.append(possible_outputs.index(prediction))\n",
    "        ground_truth.append(logits)\n",
    "    return accuracy_score(ground_truth, pred_labels)\n",
    "\n",
    "evaluate_agnews_1(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agnews(model, tokenizer, prompt_list, device=device):\n",
    "    print(\"Evaluating on AG News Dataset\")\n",
    "    possible_outputs = [\"world\", \"sports\", \"business\", \"sci/tech\"]\n",
    "    dataset = load_dataset(\"ag_news\", split=\"test\").select(range(100))\n",
    "    res = []\n",
    "    for prompt in prompt_list:\n",
    "        def classify_text(example):\n",
    "            text = example['text']\n",
    "            framed_texts = [f\"{text} {prompt} {output}.\" for output in possible_outputs]\n",
    "            encoded_inputs = [tokenizer.encode(t, return_tensors=\"pt\").to(device) for t in framed_texts]\n",
    "            \n",
    "            logits_for_outputs = []\n",
    "\n",
    "            for encoded_input in encoded_inputs:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(encoded_input)\n",
    "                    logits = outputs.logits\n",
    "                logits_for_outputs.append(logits[0, -1, :].squeeze().cpu().numpy())\n",
    "            \n",
    "            token_ids = [tokenizer.encode(output)[0] for output in possible_outputs]\n",
    "            class_logits = [logits[token_id] for logits, token_id in zip(logits_for_outputs, token_ids)]\n",
    "            pred = possible_outputs[class_logits.index(max(class_logits))]\n",
    "            example['prediction'] = possible_outputs.index(pred)\n",
    "            return example\n",
    "    \n",
    "        train_data = dataset.map(classify_text)\n",
    "        predictions = train_data['prediction']\n",
    "        ground_truth = []\n",
    "\n",
    "        for data in train_data:\n",
    "            logits = data['label']\n",
    "            ground_truth.append(logits)\n",
    "        acc = accuracy_score(ground_truth, predictions)\n",
    "        res.append(acc)\n",
    "    return res\n",
    "\n",
    "res = evaluate_agnews(model, tokenizer, topic_prompt_list)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./results/classification/\"\n",
    "files = os.listdir(dir)\n",
    "for file in files:\n",
    "    num = []\n",
    "    with open(dir + file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines) - 1):\n",
    "            res = lines[i].strip('\\n').split('\\t')[1]\n",
    "            num.append(res)\n",
    "    num = np.array(num).astype(float)\n",
    "    mean = np.mean(num)\n",
    "    \n",
    "    std = np.std(num)\n",
    "    with open(dir + file, 'a') as f:\n",
    "        f.write(f\" Mean: {mean}, STD: {std}\\n\")\n",
    "        if file.split('-')[-1].startswith('sst2'):\n",
    "            f.write(\"Total samples: 67349\")\n",
    "        else:\n",
    "            f.write(\"Total samples: 7600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8644dd181f535115d7ab48d942e03da8408d6a588f975d482130105a68652a58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
